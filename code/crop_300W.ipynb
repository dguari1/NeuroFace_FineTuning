{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f3c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ead89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit(nopython=True)\n",
    "def transform_np_allpoints(point, center, scale, resolution=256, invert=False):\n",
    "    \"\"\"Generate and affine transformation matrix.\n",
    "\n",
    "    Given a set of points, a center, a scale and a targer resolution, the\n",
    "    function generates and affine transformation matrix. If invert is ``True``\n",
    "    it will produce the inverse transformation.\n",
    "\n",
    "    Arguments:\n",
    "        point {numpy.array} -- the input 2D point\n",
    "        center {numpy.array} -- the center around which to perform the transformations\n",
    "        scale {float} -- the scale of the face/object\n",
    "        resolution {float} -- the output resolution\n",
    "\n",
    "    Keyword Arguments:\n",
    "        invert {bool} -- define wherever the function should produce the direct or the\n",
    "        inverse transformation matrix (default: {False})\n",
    "    \"\"\"\n",
    "\n",
    "    h = 200.0 * scale\n",
    "    t = np.eye(3).reshape(-1,1)\n",
    "    t[0] = resolution / h\n",
    "    t[4] = resolution / h\n",
    "    t[2] = resolution * (-center[0] / h + 0.5)\n",
    "    t[5] = resolution * (-center[1] / h + 0.5)\n",
    "    t = t.reshape(3,3)\n",
    "    \n",
    "    if invert:\n",
    "        t = np.ascontiguousarray(np.linalg.pinv(t))\n",
    "\n",
    "    new_point = t.dot(np.column_stack((point, np.ones((len(point),1)))).T)[0:2,:].T\n",
    "\n",
    "    return new_point\n",
    "\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def transform_np(point, center, scale, resolution=256, invert=False):\n",
    "    \"\"\"Generate and affine transformation matrix.\n",
    "    Given a set of points, a center, a scale and a targer resolution, the\n",
    "    function generates and affine transformation matrix. If invert is ``True``\n",
    "    it will produce the inverse transformation.\n",
    "    Arguments:\n",
    "        point {numpy.array} -- the input 2D point\n",
    "        center {numpy.array} -- the center around which to perform the transformations\n",
    "        scale {float} -- the scale of the face/object\n",
    "        resolution {float} -- the output resolution\n",
    "    Keyword Arguments:\n",
    "        invert {bool} -- define wherever the function should produce the direct or the\n",
    "        inverse transformation matrix (default: {False})\n",
    "    \"\"\"\n",
    "    _pt = np.ones(3)\n",
    "    _pt[0] = point[0]\n",
    "    _pt[1] = point[1]\n",
    "    \n",
    "    h = 200.0 * scale\n",
    "    t = np.eye(3).reshape(-1,1)\n",
    "    t[0] = resolution / h\n",
    "    t[4] = resolution / h\n",
    "    t[2] = resolution * (-center[0] / h + 0.5)\n",
    "    t[5] = resolution * (-center[1] / h + 0.5)\n",
    "    t = t.reshape(3,3)\n",
    "    \n",
    "    if invert:\n",
    "        t = np.ascontiguousarray(np.linalg.pinv(t))\n",
    "    \n",
    "    new_point = np.dot(t, _pt)[0:2]\n",
    "    \n",
    "    return new_point.astype(np.int32)\n",
    "\n",
    "def crop(image, center, scale, resolution=256.0):\n",
    "    \"\"\"Center crops an image or set of heatmaps\n",
    "    Arguments:\n",
    "        image {numpy.array} -- an rgb image\n",
    "        center {numpy.array} -- the center of the object, usually the same as of the bounding box\n",
    "        scale {float} -- scale of the face\n",
    "    Keyword Arguments:\n",
    "        resolution {float} -- the size of the output cropped image (default: {256.0})\n",
    "    Returns:\n",
    "        [type] -- [description]\n",
    "    \"\"\"  # Crop around the center point\n",
    "    \"\"\" Crops the image around the center. Input is expected to be an np.ndarray \"\"\"\n",
    "    ul = transform_np(np.array([1, 1], dtype=int), center, scale, resolution, True)\n",
    "    br = transform_np(np.array([resolution, resolution], dtype=int), center, scale, resolution, True)\n",
    "    # pad = math.ceil(torch.norm((ul - br).float()) / 2.0 - (br[0] - ul[0]) / 2.0)\n",
    "    if image.ndim > 2:\n",
    "        newDim = np.array([br[1] - ul[1], br[0] - ul[0],\n",
    "                           image.shape[2]], dtype=np.int32)\n",
    "        newImg = np.zeros(newDim, dtype=np.uint8)\n",
    "    else:\n",
    "        newDim = np.array([br[1] - ul[1], br[0] - ul[0]], dtype=np.int)\n",
    "        newImg = np.zeros(newDim, dtype=np.uint8)\n",
    "    ht = image.shape[0]\n",
    "    wd = image.shape[1]\n",
    "    newX = np.array(\n",
    "        [max(1, -ul[0] + 1), min(br[0], wd) - ul[0]], dtype=np.int32)\n",
    "    newY = np.array(\n",
    "        [max(1, -ul[1] + 1), min(br[1], ht) - ul[1]], dtype=np.int32)\n",
    "    oldX = np.array([max(1, ul[0] + 1), min(br[0], wd)], dtype=np.int32)\n",
    "    oldY = np.array([max(1, ul[1] + 1), min(br[1], ht)], dtype=np.int32)\n",
    "    newImg[newY[0] - 1:newY[1], newX[0] - 1:newX[1]\n",
    "           ] = image[oldY[0] - 1:oldY[1], oldX[0] - 1:oldX[1], :]\n",
    "\n",
    "    newImg = Image.fromarray(newImg).resize((int(resolution), int(resolution)),resample=Image.LINEAR)\n",
    "\n",
    "    return newImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3888d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (256,256)\n",
    "dfs_name = [r'../300w/face_landmarks_300w_train.csv', \n",
    "            r'../300w/face_landmarks_300w_valid_challenge.csv',\n",
    "            r'../300w/face_landmarks_300w_valid_common.csv',\n",
    "            r'../300w/face_landmarks_300w_test.csv']\n",
    "\n",
    "dfs_name_save = [r'../300w/cropped/face_landmarks_300w_train_cropped.csv', \n",
    "                 r'../300w/cropped/face_landmarks_300w_valid_challenge_cropped.csv',\n",
    "                 r'../300w/cropped/face_landmarks_300w_valid_common_cropped.csv', \n",
    "                 r'../300w/cropped/face_landmarks_300w_test_cropped.csv']\n",
    "\n",
    "new_cols = ['image_name']\n",
    "for i in range(68):\n",
    "    new_cols.append(f'landmark_{i}_x')\n",
    "    new_cols.append(f'landmark_{i}_y')\n",
    "\n",
    "    \n",
    "    \n",
    "reference_scale=195\n",
    "for k, df_name in enumerate(dfs_name):\n",
    "\n",
    "        \n",
    "    df = pd.read_csv(df_name, index_col=None)\n",
    "    data = []\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        name = row[1][0]\n",
    "\n",
    "        new_path = Path('../300w/cropped')/name\n",
    "        \n",
    "        if not new_path.is_file():\n",
    "            \n",
    "            points = row[1][4:].to_numpy(dtype=float).reshape(-1,2)\n",
    "            \n",
    "            x1,x2,y1,y2 = points[:,0].min(), points[:,0].max(),points[:,1].min(), points[:,1].max()\n",
    "            center = np.array([x2 - (x2 - x1) / 2.0, y2 - (y2 - y1) / 2.0], dtype=float)\n",
    "            center[1] = center[1] - (y2 - y1) * 0.12\n",
    "            scale = (x2 - x1 + y2 - y1) / reference_scale\n",
    "\n",
    "            im = np.asarray(Image.open(Path('../300w/images/')/name).convert('RGB'))\n",
    "            img_crop = crop(im,center,scale,256)\n",
    "            points_crop = transform_np_allpoints(points, center,scale, 256)\n",
    "\n",
    "            new_path_parents = new_path.parent\n",
    "            if not new_path_parents.exists():\n",
    "                new_path_parents.mkdir(parents=True)\n",
    "\n",
    "            img_crop.save(new_path)\n",
    "\n",
    "\n",
    "            datum = []\n",
    "            datum = [name]\n",
    "            for x,y in points_crop:\n",
    "                datum.append(x)\n",
    "                datum.append(y)\n",
    "\n",
    "\n",
    "            data.append(datum)\n",
    "\n",
    "\n",
    "\n",
    "    df_new = pd.DataFrame(data, columns=new_cols)\n",
    "    df_new.to_csv(dfs_name_save[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c18fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = pd.read_csv(r'../300w/cropped/face_landmarks_300w_valid_common_cropped.csv', index_col=0)\n",
    "challenge = pd.read_csv(r'../300w/cropped/face_landmarks_300w_valid_challenge_cropped.csv', index_col=0)\n",
    "valid  = common.append(challenge, ignore_index=True)\n",
    "valid.to_csv(r'../300w/cropped/face_landmarks_300w_valid_cropped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac3b74a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7c5ad11b677b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'datum' is not defined"
     ]
    }
   ],
   "source": [
    "datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734942f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
